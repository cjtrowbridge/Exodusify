{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5e3038",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "Import the Python modules used throughout the notebook. Make sure you have already installed the packages listed in the README (pandas, numpy, mutagen, unidecode)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4947393f",
   "metadata": {},
   "source": [
    "### Package bootstrap\n",
    "Install any missing Python packages required by this workflow so the import cell succeeds even on a fresh environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd91dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "REQUIRED_PACKAGES = {\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"numpy\": \"numpy\",\n",
    "    \"mutagen\": \"mutagen\",\n",
    "    \"unidecode\": \"Unidecode\"\n",
    "}\n",
    "\n",
    "for module_name, install_name in REQUIRED_PACKAGES.items():\n",
    "    try:\n",
    "        importlib.import_module(module_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing missing dependency: {install_name}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", install_name])\n",
    "print(\"Dependency check complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ecf47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Optional\n",
    "\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mutagen import File as MutagenFile\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db5638e",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "Define key directories (relative to the repository root) and ensure the output folder for reports exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4770fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust these paths if you relocate folders.\n",
    "REPO_ROOT = Path.cwd()\n",
    "DOWNLOAD_ROOT = REPO_ROOT / \"Downloaded\"\n",
    "SPOTIFY_PLAYLISTS = REPO_ROOT / \"spotify_playlists\"\n",
    "SHOPPING_LIST_DIR = REPO_ROOT / \"shopping_lists\"\n",
    "LIBRARY_INDEX_CSV = REPO_ROOT / \"library_index.csv\"\n",
    "\n",
    "SHOPPING_LIST_DIR.mkdir(exist_ok=True)\n",
    "print(f\"Repository root: {REPO_ROOT}\")\n",
    "print(f\"Download library: {DOWNLOAD_ROOT}\")\n",
    "print(f\"Spotify playlist CSVs: {SPOTIFY_PLAYLISTS}\")\n",
    "print(f\"Shopping/output directory: {SHOPPING_LIST_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d70d559",
   "metadata": {},
   "source": [
    "## 2. Helper functions\n",
    "Canonicalization helpers keep matching consistent between Spotify exports and local audio metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31587618",
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_ALNUM = re.compile(r\"[^a-z0-9]+\")\n",
    "FEAT_PATTERN = re.compile(r\"\\(feat\\..*?\\)\", re.IGNORECASE)\n",
    "REMIX_PATTERN = re.compile(r\"-\\s*(remaster(ed)?|remix|edit|mix).*\", re.IGNORECASE)\n",
    "AUDIO_EXTENSIONS = {'.mp3', '.flac', '.m4a', '.aac', '.ogg', '.wav', '.aiff'}\n",
    "\n",
    "def canonicalize_string(value: Optional[str]) -> str:\n",
    "    if not value:\n",
    "        return \"\"\n",
    "    normalized = unidecode(str(value))\n",
    "    normalized = FEAT_PATTERN.sub(\"\", normalized)\n",
    "    normalized = REMIX_PATTERN.sub(\"\", normalized)\n",
    "    normalized = normalized.lower()\n",
    "    normalized = NON_ALNUM.sub(\" \", normalized)\n",
    "    normalized = normalized.strip()\n",
    "    return re.sub(r\"\\s+\", \" \", normalized)\n",
    "\n",
    "def primary_artist(artists_field: Optional[str]) -> str:\n",
    "    if not artists_field or not isinstance(artists_field, str):\n",
    "        return \"\"\n",
    "    first = artists_field.split(';')[0]\n",
    "    return first.strip()\n",
    "\n",
    "def friendly_playlist_name(csv_path: Path) -> str:\n",
    "    name = csv_path.stem.replace('_', ' ')\n",
    "    return name.strip()\n",
    "\n",
    "def duration_ms_from_audio(audio_obj) -> Optional[int]:\n",
    "    if audio_obj and audio_obj.info and getattr(audio_obj.info, 'length', None):\n",
    "        return int(round(audio_obj.info.length * 1000))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b400792",
   "metadata": {},
   "source": [
    "## 3. Scan the downloaded library\n",
    "Create or refresh an auditable `library_index.csv` capturing metadata for every audio file under `Downloaded/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_downloaded_library(download_root: Path) -> pd.DataFrame:\n",
    "    records = []\n",
    "    if not download_root.exists():\n",
    "        print(f\"Download directory not found: {download_root}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for file_path in download_root.rglob('*'):\n",
    "        if not file_path.is_file() or file_path.suffix.lower() not in AUDIO_EXTENSIONS:\n",
    "            continue\n",
    "        try:\n",
    "            audio = MutagenFile(file_path)\n",
    "        except Exception as exc:\n",
    "            print(f\"Failed to read {file_path}: {exc}\")\n",
    "            audio = None\n",
    "\n",
    "        tags = getattr(audio, 'tags', None) if audio else None\n",
    "        artist_tag = None\n",
    "        title_tag = None\n",
    "        album_tag = None\n",
    "\n",
    "        if tags:\n",
    "            artist_tag = tags.get('TPE1') or tags.get('artist')\n",
    "            title_tag = tags.get('TIT2') or tags.get('title')\n",
    "            album_tag = tags.get('TALB') or tags.get('album')\n",
    "\n",
    "        artist_str = str(artist_tag.text[0]) if hasattr(artist_tag, 'text') else (artist_tag if isinstance(artist_tag, str) else None)\n",
    "        title_str = str(title_tag.text[0]) if hasattr(title_tag, 'text') else (title_tag if isinstance(title_tag, str) else None)\n",
    "        album_str = str(album_tag.text[0]) if hasattr(album_tag, 'text') else (album_tag if isinstance(album_tag, str) else None)\n",
    "\n",
    "        # Fallbacks from the path structure\n",
    "        if not artist_str:\n",
    "            artist_str = file_path.parent.name\n",
    "        if not title_str:\n",
    "            title_str = file_path.stem\n",
    "\n",
    "        records.append({\n",
    "            'file_path': file_path.relative_to(download_root).as_posix(),\n",
    "            'artist_raw': artist_str,\n",
    "            'title_raw': title_str,\n",
    "            'album_raw': album_str,\n",
    "            'artist_canonical': canonicalize_string(artist_str),\n",
    "            'title_canonical': canonicalize_string(title_str),\n",
    "            'duration_ms': duration_ms_from_audio(audio)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    if not df.empty:\n",
    "        df.sort_values(['artist_canonical', 'title_canonical', 'file_path'], inplace=True)\n",
    "    return df\n",
    "\n",
    "library_index = scan_downloaded_library(DOWNLOAD_ROOT)\n",
    "print(f\"Indexed {len(library_index):,} local tracks\")\n",
    "if not library_index.empty:\n",
    "    library_index.to_csv(LIBRARY_INDEX_CSV, index=False)\n",
    "    display(library_index.head())\n",
    "else:\n",
    "    print('Library index is empty – check DOWNLOAD_ROOT or file extensions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9e1e8",
   "metadata": {},
   "source": [
    "## 4. Load Spotify playlist exports\n",
    "Combine all CSV files in `spotify_playlists/` into a single DataFrame with helpful flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spotify_playlists(csv_root: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    if not csv_root.exists():\n",
    "        print(f\"Spotify playlist directory not found: {csv_root}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    csv_files = sorted(csv_root.glob('*.csv'))\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {csv_root}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "        except Exception as exc:\n",
    "            print(f\"Failed to read {csv_file}: {exc}\")\n",
    "            continue\n",
    "        df['playlist_name'] = friendly_playlist_name(csv_file)\n",
    "        df['is_liked'] = csv_file.name.lower() == 'liked_songs.csv'\n",
    "        df['is_top_songs'] = csv_file.name.lower().startswith('your_top_songs_')\n",
    "        rows.append(df)\n",
    "\n",
    "    merged = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n",
    "    if merged.empty:\n",
    "        return merged\n",
    "\n",
    "    merged['primary_artist'] = merged['Artist Name(s)'].apply(primary_artist)\n",
    "    merged['artist_canonical'] = merged['primary_artist'].apply(canonicalize_string)\n",
    "    merged['title_canonical'] = merged['Track Name'].apply(canonicalize_string)\n",
    "    return merged\n",
    "\n",
    "spotify_df = load_spotify_playlists(SPOTIFY_PLAYLISTS)\n",
    "print(f\"Loaded {len(spotify_df):,} Spotify rows across {spotify_df['playlist_name'].nunique() if not spotify_df.empty else 0} playlists\")\n",
    "if not spotify_df.empty:\n",
    "    display(spotify_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df321a15",
   "metadata": {},
   "source": [
    "## 5. Match Spotify tracks to the local library\n",
    "Left-join on canonical artist/title keys and filter by duration tolerance where available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb7bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DURATION_TOLERANCE_MS = 3000\n",
    "\n",
    "def match_tracks(spotify_df: pd.DataFrame, library_df: pd.DataFrame, duration_tolerance_ms: int = DURATION_TOLERANCE_MS) -> pd.DataFrame:\n",
    "    if spotify_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    if library_df.empty:\n",
    "        result = spotify_df.copy()\n",
    "        result['file_path'] = pd.NA\n",
    "        result['duration_ms_local'] = pd.NA\n",
    "        return result\n",
    "\n",
    "    lib_cols = library_df.rename(columns={'duration_ms': 'duration_ms_local'})\n",
    "    merged = spotify_df.merge(lib_cols, how='left', on=['artist_canonical', 'title_canonical'], suffixes=('_spotify', '_local'))\n",
    "\n",
    "    if 'duration_ms_local' in merged.columns:\n",
    "        mask = merged['duration_ms_local'].notna() & merged['Duration (ms)'].notna()\n",
    "        mismatched = mask & (merged['Duration (ms)'] - merged['duration_ms_local']).abs() > duration_tolerance_ms\n",
    "        merged.loc[mismatched, ['file_path', 'duration_ms_local']] = pd.NA\n",
    "    return merged\n",
    "\n",
    "matched_df = match_tracks(spotify_df, library_index)\n",
    "print(f\"Matched rows: {len(matched_df):,}\")\n",
    "if not matched_df.empty:\n",
    "    have_files = matched_df['file_path'].notna().sum()\n",
    "    print(f\"Tracks already downloaded: {have_files:,}\")\n",
    "    print(f\"Tracks missing locally: {len(matched_df) - have_files:,}\")\n",
    "    display(matched_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1594e5",
   "metadata": {},
   "source": [
    "## 6. Generate a dated shopping list\n",
    "Aggregate missing tracks across playlists and export a timestamped CSV in `shopping_lists/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ecb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_shopping_list(matched_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if matched_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    missing = matched_df[matched_df['file_path'].isna()].copy()\n",
    "    if missing.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    grouped = (\n",
    "        missing.groupby(['artist_canonical', 'title_canonical'], as_index=False)\n",
    "        .agg({\n",
    "            'primary_artist': 'first',\n",
    "            'Track Name': 'first',\n",
    "            'Album Name': lambda col: col.dropna().iloc[0] if col.dropna().any() else pd.NA,\n",
    "            'Duration (ms)': 'first',\n",
    "            'playlist_name': lambda col: sorted(set(col)),\n",
    "            'is_liked': 'any',\n",
    "            'is_top_songs': 'any'\n",
    "        })\n",
    "    )\n",
    "    grouped['Playlists_Count'] = grouped['playlist_name'].apply(len)\n",
    "    grouped['Playlists'] = grouped['playlist_name'].apply(lambda names: '; '.join(names))\n",
    "    grouped.rename(columns={\n",
    "        'primary_artist': 'Artist',\n",
    "        'Track Name': 'Title',\n",
    "        'Album Name': 'Album',\n",
    "        'Duration (ms)': 'Duration_ms',\n",
    "        'is_liked': 'Is_Liked',\n",
    "        'is_top_songs': 'Is_Top_Songs'\n",
    "    }, inplace=True)\n",
    "    columns = ['Artist', 'Title', 'Album', 'Duration_ms', 'Playlists_Count', 'Playlists', 'Is_Liked', 'Is_Top_Songs']\n",
    "    grouped = grouped[columns]\n",
    "    grouped.sort_values(['Playlists_Count', 'Is_Liked', 'Artist', 'Title'], ascending=[False, False, True, True], inplace=True)\n",
    "    return grouped\n",
    "\n",
    "shopping_df = build_shopping_list(matched_df)\n",
    "if shopping_df.empty:\n",
    "    print('All playlist tracks already exist locally – no shopping list generated.')\n",
    "else:\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    shopping_path = SHOPPING_LIST_DIR / f'shopping_list_{timestamp}.csv'\n",
    "    shopping_df.to_csv(shopping_path, index=False)\n",
    "    print(f\"Shopping list saved to {shopping_path}\")\n",
    "    display(shopping_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2cd00",
   "metadata": {},
   "source": [
    "## 7. Generate an orphaned-tracks list\n",
    "Highlight tracks that exist in `Downloaded/` but are not referenced by any current playlist snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd901248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_orphaned_tracks(matched_df: pd.DataFrame, library_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if library_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    playlist_keys = set(zip(matched_df['artist_canonical'], matched_df['title_canonical'])) if not matched_df.empty else set()\n",
    "    library_df = library_df.copy()\n",
    "    library_df['key'] = list(zip(library_df['artist_canonical'], library_df['title_canonical']))\n",
    "    mask = library_df['key'].apply(lambda key: key not in playlist_keys)\n",
    "    orphaned = library_df[mask].copy()\n",
    "    if orphaned.empty:\n",
    "        return pd.DataFrame()\n",
    "    orphaned.rename(columns={\n",
    "        'artist_raw': 'Artist',\n",
    "        'title_raw': 'Title',\n",
    "        'album_raw': 'Album',\n",
    "        'duration_ms': 'Duration_ms'\n",
    "    }, inplace=True)\n",
    "    columns = ['Artist', 'Title', 'Album', 'Duration_ms', 'file_path']\n",
    "    return orphaned[columns]\n",
    "\n",
    "orphan_df = build_orphaned_tracks(matched_df, library_index)\n",
    "if orphan_df.empty:\n",
    "    print('No orphaned tracks – every local track appears in at least one playlist snapshot.')\n",
    "else:\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    orphan_path = SHOPPING_LIST_DIR / f'orphaned_tracks_{timestamp}.csv'\n",
    "    orphan_df.to_csv(orphan_path, index=False)\n",
    "    print(f\"Orphaned-track report saved to {orphan_path}\")\n",
    "    display(orphan_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a77ff",
   "metadata": {},
   "source": [
    "## 8. Show Playlist Statistics\n",
    "Summarize key statistics about each playlist, including total tracks, matched tracks, missing tracks, and orphaned tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4bd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a57b5e3",
   "metadata": {},
   "source": [
    "## 9. Generate Playlists\n",
    "Build on these DataFrames to generate Innioasis Y1 playlist files (`.m3u8`) containing all the real tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df01e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
